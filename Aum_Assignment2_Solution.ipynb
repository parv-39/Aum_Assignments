{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEjM4DuD9BTT4SklfREanL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parv-39/Aum_Assignments/blob/main/Aum_Assignment2_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZVWqRWuAHRH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #importing pandas\n",
        "from fuzzywuzzy import fuzz #importing fuzzywuzzy(fuzzylogic)\n",
        "\n",
        "\n",
        "def clean_name(name):\n",
        "    name = name.lower() #used to convert the name to lowercase\n",
        "    cleaned = '' #empty container\n",
        "    for char in name: #checks each element of name\n",
        "        if char.isalpha() or char == ' ': #checks for alphanumeric or space in the name\n",
        "            cleaned = cleaned + char #if the value is true then it is added to cleaned\n",
        "    return cleaned #returns the name\n",
        "\n",
        "def clean_email(email):\n",
        "    email = email.lower() #used to convert the email to lowercase\n",
        "    allowed = 'abcdefghijklmnopqrstuvwxyz0123456789@.' #specifies the allowed characters in email\n",
        "    cleaned = '' #empty container\n",
        "    for char in email: #checks each element of email\n",
        "        if char in allowed: #if the elements are present in allowed(category)\n",
        "            cleaned = cleaned + char #if the value is true then it is added to cleaned\n",
        "    return cleaned #returns the name\n",
        "\n",
        "def remove_duplicate(input_file,output_file):\n",
        "    n = pd.read_csv(input_file) #used to read the input the csv file\n",
        "\n",
        "    n['clean_name'] = n['name'].map(clean_name) #applies the clean_name function on each name column\n",
        "    n['clean_email'] = n['email'].map(clean_email) #applies the clean_email function on each email column\n",
        "\n",
        "    unique_indices = [] #stores the unqiue values\n",
        "    for email, group in n.groupby('clean_email'): #groups the data by clean_email having one email and compares the same email(groupby :- it is used to aggregate/filtering data)\n",
        "        seen_names = [] #stores the processed values(seen values)\n",
        "        for indx,name in zip(group.index,group['clean_name']): #each rows data is combined(index and name from clean_name)\n",
        "            is_duplicate = False #checks for the duplicate value(and if found, it drops it)\n",
        "            for i in seen_names:\n",
        "                if fuzz.ratio(name, i) > 85: #it is used to compare the two filtered names from seen_name and checks that the fuzz ratio is above 85 or not(if not then it checks with other values in dataset)\n",
        "                    is_duplicate = True #if the fuzz ratio is above 85 then this condition is satisfied\n",
        "                    break #and it comes out the loop\n",
        "\n",
        "            if is_duplicate: #if it finds the duplicate value then it goes to next name does the same process\n",
        "                continue\n",
        "\n",
        "            seen_names.append(name) #if the name is unique then it adds to name and other names are compared with it\n",
        "            unique_indices.append(indx)\n",
        "\n",
        "    index1 = n.loc[unique_indices] #it is used to select the index which contains only unique values\n",
        "    # index1 = index1.drop(columns=['clean_name','clean_email']) #we can use this line to remove ('clean_name','clean_email')\n",
        "    index1.to_csv(output_file,index = False) #it is used to move the data in csv file and removes the index vales\n",
        "    print(f\"Deduplicated data saved to '{output_file}'\")  #f-string function to display the output\n",
        "\n",
        "input_file = \"C:\\extra\\parv_assignment2\\Customer_Data__With_Duplicates.csv\"\n",
        "remove_duplicate(input_file,'filtered.csv')"
      ]
    }
  ]
}